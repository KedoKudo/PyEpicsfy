{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This notebook is the development notes for using `bluesky` and `apstools` to conduct Tomography experiment at 6BM-A at the advanced photon source.\n",
    "\n",
    "The notebook contains the following sections:\n",
    "* preparation\n",
    "    * installation and configuration of `bluesky`+`apstools` for 6BM-A\n",
    "        * package installation\n",
    "        * meta-data broker configuration\n",
    "    * user-define functions that is useful for the tomography experiment\n",
    "* device declaration: declare `ophyd` interface for `Epics` devices\n",
    "    * device initilization\n",
    "* tomography experiment\n",
    "    * plan generation\n",
    "    * dry-run\n",
    "    * connect to devices for experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install with `pip`\n",
    "------------------\n",
    "\n",
    "__WARNING__: it is recommended to use conda to install bluesky related pacakge from now.\n",
    "\n",
    "Install `bluesky` and `apstools` with `pip` (not recommended due to dependency issues):\n",
    "\n",
    "```bash\n",
    "pip install -U pip\n",
    "pip install boltons mongoquery pims pyepics pyRestTable tzlocal jupyter suitcase matplotlib\n",
    "pip install git+https://github.com/Nikea/historydict#egg=historydict \\\n",
    "            git+https://github.com/NSLS-II/amostra#egg=amostra \\\n",
    "            git+https://github.com/NSLS-II/bluesky#egg=bluesky \\\n",
    "            git+https://github.com/NSLS-II/databroker#egg=databroker \\\n",
    "            git+https://github.com/NSLS-II/doct#egg=doct \\\n",
    "            git+https://github.com/NSLS-II/event-model#egg=event_model \\\n",
    "            git+https://github.com/NSLS-II/ophyd#egg=ophyd \\\n",
    "            git+https://github.com/NSLS-II/hklpy#egg=hklpy\n",
    "pip install apstools\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install with `conda`\n",
    "--------------------\n",
    "\n",
    "Install bluesky core packages first\n",
    "```bash\n",
    "conda install bluesky -c lightsource2-tag\n",
    "```\n",
    "\n",
    "then the apstools dependencies\n",
    "```bash\n",
    "conda install pyresttable -c prjemian\n",
    "```\n",
    "\n",
    "followed by installing apstools\n",
    "```bash\n",
    "conda install apstools -c aps-anl-dev\n",
    "```\n",
    "\n",
    "To avoid the warning/runtime-error when running RE, it is recommended to add a file named __pinned__ to the _conda-meta/_ dierectory for given environment with the following content\n",
    "```shell\n",
    "tornado<5\n",
    "```\n",
    "followed by update the tornado package through conda using \n",
    "```bash\n",
    "conda update tornado\n",
    "```\n",
    "\n",
    "> If the command above does not downgrade tornado properly, one can use `conda install tornado==4.5.3` to force reinstall a lower version.\n",
    "\n",
    "Finally, install jupyter and matplotlib\n",
    "```bash\n",
    "conda install jupyter matplotlib\n",
    "```\n",
    "\n",
    "> alternatively, one can setup a `.conda.rc` file in the home directory to specify the channels\n",
    "```\n",
    "channels:\n",
    "    - defaults\n",
    "    - conda-forge\n",
    "    - lightsource2-tag\n",
    "    - lightsource2-dev\n",
    "    - aps-anl-tag\n",
    "    - aps-anl-dev\n",
    "    - prjemian\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then configure MongoDB for meta-data handling\n",
    "\n",
    "The following YAML config file should be place under `~/.config/` to use MongoDB as meta-data handler.\n",
    "\n",
    "```yml\n",
    "# ~/.config/databroker/mongodb_config.yml\n",
    "\n",
    "description: 'heavyweight shared database'\n",
    "metadatastore:\n",
    "   module: 'databroker.headersource.mongo'\n",
    "   class: 'MDS'\n",
    "   config:\n",
    "       host: 'otz.aps.anl.gov'\n",
    "       port: 27017\n",
    "       database: 'metadatastore-production-v1'\n",
    "       timezone: 'US/Central'\n",
    "assets:\n",
    "   module: 'databroker.assets.mongo'\n",
    "   class: 'Registry'\n",
    "   config:\n",
    "       host: 'otz.aps.anl.gov'\n",
    "       port: 27017\n",
    "       database: 'filestore-production-v1'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the data base\n",
    "from databroker import Broker\n",
    "db = Broker.named(\"mongodb_config\")\n",
    "\n",
    "# subscribe both mongodb and callback to runtime engine\n",
    "import bluesky\n",
    "from bluesky import RunEngine\n",
    "from bluesky.callbacks.best_effort import BestEffortCallback\n",
    "\n",
    "RE = RunEngine({})\n",
    "RE.subscribe(db.insert)\n",
    "RE.subscribe(BestEffortCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import getpass\n",
    "\n",
    "socket.gethostname()\n",
    "getpass.getuser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata for diagnostics\n",
    "import os\n",
    "from datetime import datetime\n",
    "import apstools\n",
    "import ophyd\n",
    "import socket\n",
    "import getpass\n",
    "\n",
    "HOSTNAME = socket.gethostname() or 'localhost'\n",
    "USERNAME = getpass.getuser() or '6-BM-A user'\n",
    "RE.md['beamline_id'] = 'APS 6-BM-B'\n",
    "RE.md['proposal_id'] = 'internal test'\n",
    "RE.md['pid'] = os.getpid()\n",
    "RE.md['login_id'] = USERNAME + '@' + HOSTNAME\n",
    "RE.md['BLUESKY_VERSION'] = bluesky.__version__\n",
    "RE.md['OPHYD_VERSION'] = ophyd.__version__\n",
    "RE.md['apstools_VERSION'] = apstools.__version__\n",
    "RE.md['SESSION_STARTED'] = datetime.isoformat(datetime.now(), \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user defined function goes here\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# 1. checking the APS beam status\n",
    "import apstools.devices as APS_devices\n",
    "\n",
    "aps = APS_devices.ApsMachineParametersDevice(name=\"APS\")\n",
    "\n",
    "pprint(aps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now from the hardware end, we need additional setup IOC (soft) for this status, recommended method `VME`\n",
    "\n",
    "Here is a quick example from 2BM\n",
    "```python\n",
    "instrument_in_use = EpicsSignalRO(\n",
    "    \"2bm:instrument_in_use\", \n",
    "    name=\"instrument_in_use\")\n",
    "\n",
    "def operations_in_2bmb():\n",
    "    \"\"\"returns True if allowed to use X-ray beam in 2-BM-B station\"\"\"\n",
    "    v = instrument_in_use.value\n",
    "    enums = instrument_in_use.enum_strs\n",
    "    return enums[v] == \"2-BM-B\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. assume we have the same setup describe above\n",
    "\n",
    "from ophyd import EpicsSignalRO\n",
    "\n",
    "instrument_in_use = EpicsSignalRO(\"6bm:instrument_in_use\", name=\"instrument_in_use\")\n",
    "\n",
    "RE.md['INSTRUMENT_IN_USE'] = instrument_in_use.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(instrument_in_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. check ambien light in hutch\n",
    "import apstools.synApps_ophyd\n",
    "\n",
    "# grab all calcs\n",
    "calcs = apstools.synApps_ophyd.userCalcsDevice(\"6bma1:\", name=\"calcs\", )\n",
    "\n",
    "# calc1.ch8 is ambient light checker\n",
    "#calc1 = calcs.calc1\n",
    "hutch_light_on = bool(calcs.calc1.val..get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calcs.calc1.val.get() ,hutch_light_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. define the ENV VAR denote the experiment nature\n",
    "# NOTE:\n",
    "#    the return value of instrument_in_use is not yet decided\n",
    "\n",
    "# conducting experiment mode\n",
    "in_production = aps.inUserOperations \\\n",
    "            and (instrument_in_use.get() in (1, \"6-BM-A\")) \\\n",
    "            and (not hutch_light_on)\n",
    "\n",
    "# testing mode, supercede in_production\n",
    "in_dryrun = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(in_production, aps.inUserOperations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary import\n",
    "import apstools.devices as APS_devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bluesky.suspenders import SuspendFloor\n",
    "\n",
    "if in_production:\n",
    "    # define the real shutter used at 6BMA@APS\n",
    "    # NOTE: \n",
    "    #   this requires connection to the hardware, otherwise a connection error will be raised\n",
    "\n",
    "    A_shutter = APS_devices.ApsPssShutterWithStatus(\n",
    "            \"6bmb1:rShtrA:\",\n",
    "            \"PA:06BM:STA_A_FES_OPEN_PL\",\n",
    "            name=\"A_shutter\",\n",
    "        )\n",
    "    A_shutter.pss_state\n",
    "    # no scans until A_shutter is open\n",
    "    suspend_A_shutter = SuspendFloor(A_shutter.pss_state, 1)\n",
    "    #suspend_A_shutter.install(RE)\n",
    "    RE.install_suspender(suspend_A_shutter)\n",
    "    \n",
    "    # no scans if aps.current is too low\n",
    "    suspend_APS_current = SuspendFloor(aps.current, 2, resume_thresh=10)\n",
    "    RE.install_suspender(suspend_APS_current)\n",
    "\n",
    "else:\n",
    "    # first, a simulated shutter to demonstrate the design of epics controled shutter\n",
    "\n",
    "    A_shutter = APS_devices.SimulatedApsPssShutterWithStatus(name=\"A_shutter\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To open a shutter, use `A_shutter.open`. \n",
    "Similarly, the shutter can be closed with `A_shutter.close`.\n",
    "One can also check the current status of the shutter using `A_shutter.isOpen`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## area detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from pathlib import Path, PureWindowsPath\n",
    "\n",
    "# production control ENV vars\n",
    "ADPV_prefix = \"1idPG2\"   # AreaDetector prefix\n",
    "# OUTPUT_ROOT = \"/home/beams/S6BM/user_data\"\n",
    "OUTPUT_ROOT = \"Y:\\\\\"\n",
    "\n",
    "# -----------------------\n",
    "# -- user config block --\n",
    "# -----------------------\n",
    "CYCLE = \"2019-1\"\n",
    "EXPID = \"internal_apr19\"\n",
    "USER  = EXPID\n",
    "SAMPLE = \"test\"\n",
    "\n",
    "FILE_PATH = str(PureWindowsPath(Path(\"/\".join([OUTPUT_ROOT, CYCLE, EXPID, \"tomo\", SAMPLE])+\"/\")))+'\\\\'\n",
    "# FILE_PATH =  os.path.join(OUTPUT_ROOT, CYCLE, EXPID, \"tomo\", SAMPLE) + os\n",
    "FILE_PREFIX = SAMPLE\n",
    "\n",
    "# show where files will be stored\n",
    "print(FILE_PATH)\n",
    "print(FILE_PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As of today, there is still no support for Python class enclosure, so we have to make a class for the detector\n",
    "from ophyd import AreaDetector\n",
    "from ophyd import SingleTrigger\n",
    "from ophyd import ADComponent\n",
    "from ophyd import PointGreyDetectorCam\n",
    "from ophyd import ProcessPlugin\n",
    "from ophyd import TIFFPlugin\n",
    "from ophyd import sim\n",
    "\n",
    "# class PointGreyDetectorCam6BM(PointGreyDetectorCam):\n",
    "#     \"\"\"Extend the default Point Grey detector cam\"\"\"\n",
    "#     frame_rate_on_off = ADComponent(EpicsSignalWithRBV, \"FrameRateOnOff\")\n",
    "\n",
    "\n",
    "class PointGreyDetector6BM(SingleTrigger, AreaDetector):\n",
    "    \"\"\"Point Gray area detector used at 6BM\"\"\"\n",
    "    # cam component\n",
    "    cam = ADComponent(PointGreyDetectorCam, \"cam1:\")\n",
    "    \n",
    "    # proc plugin\n",
    "    proc1 = ADComponent(ProcessPlugin, suffix=\"Proc1:\")\n",
    "    \n",
    "    # tiff plugin\n",
    "    tiff1 = ADComponent(\n",
    "        TIFFPlugin,\n",
    "        suffix=\"TIFF1:\",\n",
    "#         root=OUTPUT_ROOT,                       # for databroker\n",
    "#         write_path_template=FILE_PATH,          # for EPICS AD\n",
    "    )\n",
    "    \n",
    "\n",
    "# ------------------------------------\n",
    "# ----- Instantiate the detector ----- \n",
    "# ------------------------------------\n",
    "\n",
    "# Area Detector (AD) config block\n",
    "config_cam = {\n",
    "    \"num_images\":     1,           # number of images (nFrame)\n",
    "    \"image_mode\":     \"Multiple\",  #\n",
    "    \"trigger_mode\":   \"Internal\",  #\n",
    "    \"acquire_time\":   0.05,           # exposure time (fExposureTime)\n",
    "    \"acquire_period\": 0.05+0.01,      #\n",
    "    \"gain\":           5,           # detector gain [0~30]\n",
    "}\n",
    "\n",
    "config_proc1 = {\n",
    "    \"enable\":           1,  # toggle on proc1\n",
    "    \"enable_filter\":    1,  # enable filter\n",
    "    \"num_filter\":       5,  # change number_filtered in proc1 (same as nFrame)\n",
    "    \"reset_filter\":     1,  # reset number_filtered\n",
    "}\n",
    "\n",
    "config_tiff1 = {\n",
    "    \"nd_array_port\":    \"PROC1\",      # switch port for TIFF plugin\n",
    "    \"file_write_mode\":  \"Stream\",     # change write mode\n",
    "    \"auto_save\":        \"Yes\",        # turn on file save\n",
    "    \"file_path\":        FILE_PATH,    # set file path\n",
    "    \"file_name\":        FILE_PREFIX,  # img name prefix\n",
    "}\n",
    "\n",
    "\n",
    "if in_production or in_dryrun:\n",
    "    pg2_det = PointGreyDetector6BM(\"1idPG2:\", name='pg2_det')\n",
    "    pg2_det.read_attrs.append('tiff1')  # this is very important\n",
    "    \n",
    "    # catch timeout error in case detector not responding\n",
    "    try:\n",
    "        for k, v in config_cam.items():     pg2_det.cam.stage_sigs[k]   = v\n",
    "        for k, v in config_proc1.items():   pg2_det.proc1.stage_sigs[k] = v\n",
    "        for k, v in config_tiff1.items():   pg2_det.tiff1.stage_sigs[k] = v\n",
    "    except TimeoutError as _exc:\n",
    "        print(f\"{_exc}\\n !! Could not connect with area detector {pg2_det}\")\n",
    "    \n",
    "else:\n",
    "    pg2_det = sim.noisy_det  # use ophyd simulated detector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg2_det.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## motor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ophyd import MotorBundle\n",
    "from ophyd import Component\n",
    "from ophyd import EpicsMotor\n",
    "\n",
    "# NOTE: \n",
    "#    the PV for actual motors is still unknown\n",
    "class TomoStage(MotorBundle):\n",
    "    #rotation\n",
    "    preci = Component(EpicsMotor, \"6bmpreci:m1\",\n",
    "                      name='preci',\n",
    "                     )\n",
    "    \n",
    "    samX = Component(EpicsMotor, \"6bma1:m19\",\n",
    "                     name='samX',\n",
    "                    )\n",
    "    \n",
    "    samY = Component(EpicsMotor, \"6bma1:m18\",\n",
    "                     name=\"samY\",\n",
    "                    )\n",
    "\n",
    "if in_production or in_dryrun:\n",
    "    tomostage = TomoStage(name='tomostage')\n",
    "\n",
    "    samx  = tomostage.samX\n",
    "    samy  = tomostage.samY\n",
    "    preci = tomostage.preci\n",
    "    \n",
    "    dummy = sim.motor\n",
    "\n",
    "else:\n",
    "    tomostage = MotorBundle()\n",
    "    tomostage.preci = sim.motor\n",
    "    tomostage.samX = sim.motor\n",
    "    tomostage.samY = sim.motor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tomography experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scan plans\n",
    "\n",
    "Define the scan parameters within plan functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# ----- Scan parameters -----\n",
    "# ---------------------------\n",
    "n_white        =  10\n",
    "n_dark         =  10\n",
    "samOutDist     = -2.00              # mm\n",
    "omega_step     =  0.25              # degrees\n",
    "acquire_time   =  0.05              # sec\n",
    "acquire_period = acquire_time+0.01  # sec\n",
    "time_wait      = acquire_period*2   # sec\n",
    "omega_start    =  0\n",
    "omega_end      =  5\n",
    "\n",
    "number_of_projections = int(abs(omega_end-omega_start)/omega_step)+1  # 0 ~ 180\n",
    "\n",
    "test_mode = True  # skip wait time during plan summarize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# ----- base detector configuration ----- \n",
    "# ---------------------------------------\n",
    "\n",
    "# NOTE:\n",
    "# -- gradually building a comprehensive list of options for the configuration\n",
    "# -- use \n",
    "\n",
    "# Area Detector (AD) config block\n",
    "config_cam = {\n",
    "    \"num_images\":     1,           # number of images (nFrame)\n",
    "    \"image_mode\":     \"Multiple\",  #\n",
    "    \"trigger_mode\":   \"Internal\",  #\n",
    "    \"acquire_time\":   0.05,        # exposure time (fExposureTime)\n",
    "    \"acquire_period\": 0.05+0.01,   #\n",
    "    \"gain\":           5,           # detector gain [0~30]\n",
    "}\n",
    "\n",
    "config_proc1 = {\n",
    "    \"enable\":           1,  # toggle on proc1\n",
    "    \"enable_filter\":    1,  # enable filter\n",
    "    \"num_filter\":       5,  # change number_filtered in proc1 (same as nFrame)\n",
    "    \"reset_filter\":     1,  # reset number_filtered\n",
    "}\n",
    "\n",
    "config_tiff1 = {\n",
    "    \"nd_array_port\":    \"PROC1\",      # switch port for TIFF plugin\n",
    "    \"file_write_mode\":  \"Stream\",     # change write mode\n",
    "    \"auto_save\":        \"Yes\",        # turn on file save\n",
    "    \"file_path\":        FILE_PATH,    # set file path\n",
    "    \"file_name\":        FILE_PREFIX,  # img name prefix\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ophyd.status import DeviceStatus\n",
    "\n",
    "import bluesky.plans         as bp\n",
    "import bluesky.preprocessors as bpp\n",
    "import bluesky.plan_stubs    as bps\n",
    "\n",
    "def cleanup():\n",
    "    pass\n",
    "\n",
    "\n",
    "def tiff_io_wait():\n",
    "    \"\"\"\n",
    "    mimic io wait for the tiff plugin\n",
    "    \n",
    "    while (epics_get(\"1idPG2:TIFF1:Capture_RBV\") != \"Done\") {\n",
    "        sleep(0.05)\n",
    "        }\n",
    "    \"\"\"\n",
    "    while (pg2_det.tiff1.capture.get() != \"Done\"):\n",
    "        yield from bps.sleep(time_wait)\n",
    "\n",
    "def cam_io_wait():\n",
    "    \"\"\"\n",
    "    mimicing the waiting scheme in original epics script\n",
    "    \n",
    "    while ( (epics_get(\"1idPG2:cam1:NumImages_RBV\")-epics_get(\"1idPG2:cam1:NumImagesCounter_RBV\")) != 0 ) {\n",
    "            sleep(fExposureTime + trigger_wait)\n",
    "            trigger_count++\n",
    "            if ( (time()-tic) > 30 ) {\n",
    "                sendemailalert \"Pointgray Acquire timeout\"\n",
    "                sleep(600)\n",
    "            }\n",
    "        }\n",
    "\n",
    "    \"\"\"\n",
    "    _st = DeviceStatus(pg2_det.cam)\n",
    "    \n",
    "    def _call_back(value, timestamp, **kwargs):\n",
    "        if pg2_det.cam.num_images.get() == value:\n",
    "            _st._finished(success=True)\n",
    "    \n",
    "    pg2_det.cam.num_images_counter.subscribe(_call_back)\n",
    "    \n",
    "    while (pg2_det.cam.num_images.get() < pg2_det.cam.num_images_counter.get()): \n",
    "        yield from bps.sleep(time_wait)\n",
    "\n",
    "\n",
    "\n",
    "def collect_background(n):\n",
    "    \"\"\"scan plan for white/dark background collection (no motor motion)\"\"\"    \n",
    "    yield from bps.mv(pg2_det.cam.acquire, 0)\n",
    "    \n",
    "    for k,v in {\n",
    "        \"num_capture\": n,\n",
    "        \"capture\":     1,\n",
    "    }.items(): pg2_det.tiff1.stage_sigs[k] = v\n",
    "    \n",
    "    for k,v in {\n",
    "        \"reset_filter\":  1,\n",
    "    }.items(): pg2_det.proc1.stage_sigs[k] = v\n",
    "        \n",
    "    for k,v in {\n",
    "        \"trigger_mode\": \"Internal\",\n",
    "        \"image_mode\":   \"Multiple\",\n",
    "        \"num_images\":   n,\n",
    "    }.items(): pg2_det.cam.stage_sigs[k] = v\n",
    "    \n",
    "    @bpp.stage_decorator([pg2_det])\n",
    "    @bpp.run_decorator()\n",
    "    @bpp.finalize_decorator(cleanup)  # finally block\n",
    "    def scan():\n",
    "        yield from bps.trigger_and_read([pg2_det])  # can trigger_and_read prevent buffer async issue?\n",
    "    \n",
    "#         if not test_mode: \n",
    "#             yield from cam_io_wait()\n",
    "#             yield from tiff_io_wait()\n",
    "    \n",
    "    return (yield from scan())\n",
    "        \n",
    "\n",
    "def collect_projections_alt():\n",
    "    \"\"\"translated directly from previous epics macro\"\"\"\n",
    "    yield from bps.mv(pg2_det.cam.capture, 0)  # stop the camera \n",
    "    \n",
    "    # set staging paras\n",
    "    # -- tiff1 plugin\n",
    "    for k, v in {\n",
    "        \"num_capture\": 1,                         # one images at a time\n",
    "        \"capture\":     1,                         # enable tiff1 plugin, 1 is \"Capture\"\n",
    "    }.items(): pg2_det.tiff1.stage_sigs[k] = v\n",
    "    \n",
    "    # -- proc1 plugin\n",
    "    for k, v in {\n",
    "        \"enable\":           1,  # toggle on proc1\n",
    "        \"reset_filter\":     1,  # reset number_filtered\n",
    "    }.items(): pg2_det.proc1.stage_sigs[k] = v\n",
    "    \n",
    "    # -- cam plugin\n",
    "    for k, v in {\n",
    "        \"num_images\":   1,      # one projection at a time\n",
    "    }.items(): pg2_det.cam.stage_sigs[k] = v\n",
    "   \n",
    "    # now the scan step\n",
    "    @bpp.stage_decorator([pg2_det])\n",
    "    @bpp.run_decorator()\n",
    "    @bpp.finalize_decorator(cleanup)\n",
    "    def scan_closure():\n",
    "        for ang in np.linspace(omega_start, omega_end, number_of_projections):\n",
    "            yield from bps.mv(preci, ang)\n",
    "            yield from bps.trigger_and_read([pg2_det])\n",
    "#             if not test_mode:\n",
    "#                 yield from cam_io_wait()\n",
    "#                 yield from tiff_io_wait()\n",
    "    \n",
    "    return (yield from scan_closure())\n",
    "\n",
    "\n",
    "def collect_projections():\n",
    "    \"\"\"scan plan for projection image collections (step scans)\"\"\"\n",
    "    \n",
    "    yield from bp.scan(\n",
    "        [pg2_det], \n",
    "        preci,        # rotary motor\n",
    "        omega_start, omega_end, number_of_projections,\n",
    "    )  # interanlly using trigger and wait, so it should wait for the image to finish transfer from cam to tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tomo_scan():\n",
    "    \"\"\"\n",
    "    The master plan pass to RE for\n",
    "    \n",
    "    1. pre-white-field background collection\n",
    "    2. projection collection\n",
    "    3. post-white-field background collection\n",
    "    4. post-dark-field background collection\n",
    "    \"\"\"\n",
    "    # prep, set the default values for detectors\n",
    "    # NOTE:\n",
    "    #    This part is run on the Jupyter end, and send to device\n",
    "    #    during execution by RE\n",
    "    for k, v in config_cam.items():     pg2_det.cam.stage_sigs[k]   = v\n",
    "    for k, v in config_proc1.items():   pg2_det.proc1.stage_sigs[k] = v\n",
    "    for k, v in config_tiff1.items():   pg2_det.tiff1.stage_sigs[k] = v\n",
    "    \n",
    "    # frist, n_white background\n",
    "    current_samx = samx.position\n",
    "    yield from bps.mv(samx, current_samx + samOutDist)\n",
    "    yield from collect_background(n_white)\n",
    "    yield from bps.mv(samx, current_samx)\n",
    "    \n",
    "    # then, projection images\n",
    "    yield from collect_projections()\n",
    "    \n",
    "    # now collect the post white field backgrounds\n",
    "    current_samx = samx.position\n",
    "    yield from bps.mv(samx, current_samx - samOutDist)\n",
    "    yield from collect_background(n_white)\n",
    "    yield from bps.mv(samx, current_samx)\n",
    "    \n",
    "    # finally, collect the dark field images\n",
    "    yield from bps.mv(A_shutter, \"close\")\n",
    "    yield from collect_background(n_dark)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now pass the plan to summarizer for sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bluesky.simulators import summarize_plan\n",
    "\n",
    "test_mode = True\n",
    "\n",
    "summarize_plan(tomo_scan())\n",
    "\n",
    "test_mode = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then pass it to RunEngine for data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE(tomo_scan())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
